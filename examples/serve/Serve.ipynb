{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61281094-e991-4bc3-ad7b-a7357bb5fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from weave import weaveflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1315db-3db8-4208-9fb5-5250734de1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.init('weaveflow-serving4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a6b06-f47b-456a-b67f-2220d7016dbb",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf899362-21cc-43d8-bac0-19a5d929f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.type()\n",
    "class Add1Model(weaveflow.Model):\n",
    "    llm: weaveflow.ChatModel\n",
    "    \n",
    "    @weave.op()\n",
    "    def predict(self, operand: str) -> str:\n",
    "        response = self.llm.complete([{'role': 'user', 'content': f'{operand} + 1 ='}])\n",
    "        return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08293cc0-97fb-43e7-b855-459da881abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Add1Model(weaveflow.OpenaiChatModel('gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1130fc-6ffb-459f-9d80-4a05866212e3",
   "metadata": {},
   "source": [
    "## Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceab707-8260-4d49-8519-bda4cde212d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27384d8c-2745-4663-a4e7-5c69ab038239",
   "metadata": {},
   "source": [
    "## Publish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217aabd7-3d4a-43d0-9424-b904fc92aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = weave.publish(model, 'great_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f7bef-d45a-4920-a39a-7a8afb6e84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ca3b3-3505-4e8a-b4d5-e8ce2ac71708",
   "metadata": {},
   "source": [
    "## Serve model\n",
    "\n",
    "Run the following command (the weave server is only available in the weave repo at the moment. Coming soon).\n",
    "\n",
    "```\n",
    "MODEL_REF=<ref_from_above>  PROJECT_NAME=shawn/weaveflow-serving uvicorn weave.model_server:app\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
