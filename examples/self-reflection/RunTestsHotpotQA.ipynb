{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2ff44-e8ea-4da8-991d-d7483f9adc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import weave\n",
    "from weave import weaveflow\n",
    "import models\n",
    "import example_adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d31c8-17d9-48fc-90f1-0e654926334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.init('self-reflection5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd12298-a34a-45bf-ad20-a9c7d7c56556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = weaveflow.publish_huggingface_dataset(\"hotpot_qa\", 'distractor', \"validation\", 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f690c-0ad2-4296-8528-bceb04391acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.type()\n",
    "class HotpotExampleAdaptor(example_adaptor.ExampleAdaptor):\n",
    "    @weave.op()\n",
    "    def example_to_prompt(self, example: typing.Any) -> typing.Any:\n",
    "        context_sentences = example['context']['sentences']\n",
    "        context = '\\n'.join('\\n'.join(cs) for cs in context_sentences)\n",
    "        question = example['question']\n",
    "        return f'Context\\n\\n{context}\\n\\n{question}'\n",
    "\n",
    "adaptor = HotpotExampleAdaptor(\"Please provide a minimal answer, with no accompanying explanation and no punctuation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55424fd-6834-4b9f-bb93-a80657a82c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = weaveflow.OpenaiChatModel('gpt-3.5-turbo')\n",
    "single_step_model = models.SingleStepModel(chat_model, adaptor)\n",
    "reflect_model = models.SelfReflectModel(chat_model, adaptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b7982-a840-4ff2-abb0-494212a96508",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def example_answer(example: typing.Any) -> str:\n",
    "    return example['answer']\n",
    "\n",
    "eval_exact = weaveflow.EvaluateExactMatch(example_answer)\n",
    "eval_chat_model = weaveflow.StructuredOutputChatModelSystemPrompt(\n",
    "    weaveflow.OpenaiChatModel('gpt-3.5-turbo', 0.7))\n",
    "@weave.op()\n",
    "def make_llm_eval_messages(example: typing.Any, prediction: typing.Any) -> typing.Any:\n",
    "    prompt_args = {\n",
    "        'question': example['question'],\n",
    "        'answer': example['answer'],\n",
    "        'prediction': prediction\n",
    "    }\n",
    "    prompt = \"\"\"\n",
    "Please score the following, on a scale of 1-5, with one being worse. Also provide your rationale.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "Correct answer: {prediction}\n",
    "\"\"\".format(**prompt_args)\n",
    "    return [{'role': 'user', 'content': prompt}]\n",
    "eval_llm = weaveflow.EvaluateLLM(eval_chat_model, make_llm_eval_messages)\n",
    "eval = weaveflow.EvaluateMulti({\n",
    "    'exact': eval_exact,\n",
    "    'llm': eval_llm\n",
    "})\n",
    "\n",
    "evaluation_single = weaveflow.EvaluateNamedSteps(['final_answer'], eval)\n",
    "evaluation_reflect = weaveflow.EvaluateNamedSteps(['first_answer', 'final_answer'], eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8f2eb-4e6f-4c06-a38a-e6e17789d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "weaveflow.evaluate(evaluation_single, dataset_ref, single_step_model)\n",
    "weaveflow.evaluate(evaluation_reflect, dataset_ref, reflect_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
