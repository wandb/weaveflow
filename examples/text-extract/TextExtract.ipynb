{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238796ab-6d09-4bbb-8b77-7b9a7c897801",
   "metadata": {},
   "source": [
    "## Example overview\n",
    "\n",
    "This notebook shows how to use Weave to build text extraction capabilities using LLMs.\n",
    "\n",
    "It covers:\n",
    "- [x] experimenting with different techniques for text extraction\n",
    "- [x] using LLMs for text extraction\n",
    "- [x] prompt experimentation\n",
    "- [x] rigorous evaluation of text extraction models\n",
    "- [ ] model serving and monitoring\n",
    "- [ ] production feedback capture\n",
    "- [ ] improving evaluation datasets from production data\n",
    "- [ ] evolving the problem definition\n",
    "\n",
    "All of the above is tracked and versioned using Weave, and presented in Weave's UI for analysis.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Install the weave package from the weaveflow branch:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/wandb/weave@weaveflow\n",
    "```\n",
    "\n",
    "Run the prototype UI locally:\n",
    "\n",
    "```\n",
    "weave ui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabe6af-3746-46af-9335-6caa8e67d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import typing\n",
    "import weave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68ae35-cec2-43e5-9047-162aa129d9ba",
   "metadata": {},
   "source": [
    "Everything will be tracked in the following W&B project, which will be auto-created if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d042799-0d61-415f-87e9-0c84e333759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'text-extract52'\n",
    "weave.init(PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb471e-1297-4679-8303-0b7da34ff89a",
   "metadata": {},
   "source": [
    "This example shows extracting fields from \"Articles of Incorporation\" documents (these are legal documents that filed are when a company is formed). The example documents are generated by gpt-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd984de5-0811-4fc9-b689-26bc475adb39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6c54c-ab3c-4cd4-9e79-3a0a09f44bdf",
   "metadata": {},
   "source": [
    "An example document looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442171d2-523c-4da5-afed-953bdc5ac684",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc = open('example_data/Articles_of_Incorporation_Real_Example_3.txt').read()\n",
    "print(example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920927d0-2abc-43a1-99e2-6f2f84783c2b",
   "metadata": {},
   "source": [
    "The labels look like this. For now we want to extract the company name, and the initial number of stock shares. Only a subset of the example documents have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561540c1-c578-4382-a3e8-70b65a16db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(open(os.path.join(\"example_data\", \"labels.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be29380-39e4-4f78-a3f9-610a650f3349",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We create table with \"example\" and \"label\" columns, and then publish it with weave to start versioning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ecdb7-3cea-4f4a-a672-055d2c4ac965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our dataset\n",
    "def read_dataset():\n",
    "    dataset_rows = []\n",
    "    raw_labels = json.load(open(os.path.join(\"example_data\", \"labels.json\")))\n",
    "    for example_id, label in raw_labels.items():\n",
    "        example = open(os.path.join('example_data', example_id + '.txt')).read()\n",
    "        dataset_rows.append(\n",
    "            {\"id\": example_id, \"example\": example, \"label\": label})\n",
    "    return dataset_rows\n",
    "\n",
    "# Construct and publish to W&B\n",
    "dataset = weave.Dataset(read_dataset())\n",
    "dataset_ref = weave.publish(dataset, \"eval_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153dfa6-7e81-42ae-aa51-2a6e6cc9bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whatever_ref = weave.publish({'hi': 'adam'}, 'my-stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecffb2ea-2efb-413b-a300-afe526397389",
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.ref('my-stuff').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca0f35-b984-4e48-b653-f0409d43958a",
   "metadata": {},
   "source": [
    "Click the link printed above to view the published dataset in the UI.\n",
    "\n",
    "### Editing data in the UI\n",
    "\n",
    "There are a few missing labels! Double-click the table cells to edit the data in the UI, and fix the labels. Then press the commit version to commit the changes.\n",
    "\n",
    "To get the fixed dataset back in Python, you can grab the latest version with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6448ed-59a7-40d7-8a0f-95ae745647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = weave.ref('eval_dataset')\n",
    "dataset_ref.get().rows[2]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28a904-12e5-4cb1-9920-9c01e9d21f3b",
   "metadata": {},
   "source": [
    "## Tracking function calls with weave.op\n",
    "\n",
    "Annotate a python function with weave.op to keep track of its code, log and log traces of its calls.\n",
    "\n",
    "This is a simple baseline that uses regexes to try to extract the fields we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1852db4-3c58-4cd3-a097-873122698921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def predict_name(doc: str) -> typing.Any:\n",
    "    match = re.search(r'name.*is ([^.]*)(\\.|\\n)', doc)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def predict_shares(doc: str) -> typing.Any:\n",
    "    match = re.search(r'[Ss]hares.*?([\\d,]+)', doc)\n",
    "    return match.group(1).replace(',', '') if match else None\n",
    "\n",
    "@weave.op()\n",
    "def predict(doc: str) -> typing.Any:\n",
    "    return {\n",
    "        'name': predict_name(doc),\n",
    "        'shares': predict_shares(doc)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a77410-e7bb-4573-95b1-4561976d60e2",
   "metadata": {},
   "source": [
    "Ops behave like normal functions. But their code is captured and versioned, and their calls are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982a426-3ae6-4718-8351-d12808577566",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051aba72-8d33-4d1d-98d6-2efa6cde189c",
   "metadata": {},
   "source": [
    "Click the link printed above to see all the calls of our op.\n",
    "\n",
    "If you change the predict function's code by editing it and rerunning the jupyter cell where it's defined, the next time you call it you'll get a new version of the op. Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cd19a-728f-49c5-b3cd-7c6c6457793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we iterate through all the rows in the dataset, performing predictions\n",
    "for row in dataset_ref.get().rows:\n",
    "    print(predict(row['example']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fdd07-8cf2-4b83-8151-ef91d0989812",
   "metadata": {},
   "source": [
    "Go back to the UI to see all the calls we just made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839cc82-1692-40ef-a522-9a09240a4c6f",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "A \"model\" is simply a combination of data (which can be configuration, trained model weights, or anything else), and code that says how to execute the model.\n",
    "\n",
    "Use the pattern below to construct a model.\n",
    "\n",
    "The `@weave.type()` decorator makes classes that are automatically published and versioned as they are used.\n",
    "- Like python's dataclasses feature, you must annotate attributes with python types.\n",
    "- You can add methods that are weave ops.\n",
    "\n",
    "Inherit from weave.Model to categorize this object as a Model in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d12d45-914d-4865-8cb1-70a674e419ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.type()\n",
    "class RegexModel(weave.Model):\n",
    "    # Data: configuration for this model\n",
    "    extract_name: bool\n",
    "    extract_shares: bool\n",
    "\n",
    "    # Code: how should this model execute on an example?\n",
    "    @weave.op()\n",
    "    def predict(self, doc: str) -> typing.Any:\n",
    "        return {\n",
    "            'name': predict_name(doc) if self.extract_name else None,\n",
    "            'shares': predict_shares(doc) if self.extract_shares else None\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96505cd8-0798-45e5-ba71-b36e1328a03f",
   "metadata": {},
   "source": [
    "You can instantiate @weave.type() objects like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593bea7-2b4c-4bed-adc4-904fba5ff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_model = RegexModel(extract_name=False, extract_shares=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f9246-077f-4a99-a395-1c58ba6d198a",
   "metadata": {},
   "source": [
    "And then call methods on them like normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb6655-2f42-4963-82a3-5c14f9660cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_model.predict(example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3fe91-e9c8-4d1c-a57b-0f92647b8d74",
   "metadata": {},
   "source": [
    "If we change the model's configuration, or its definition (by changing its code), Weave will ensure that a new\n",
    "version is published. Here we create a new model configuration and use it. There will be two versions of our RegexModel in the UI after this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41e6e2-eb81-43a0-97a3-70b918f2c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_model = RegexModel(extract_name=True, extract_shares=True)\n",
    "regex_model.predict(example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24f6e4-2077-4f51-b16a-8dc0566267d8",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation is used to give us apple-to-apples comparison of models.\n",
    "\n",
    "You can think of evaluation as simply a function that takes a dataset and a model as input, and produces metrics as output.\n",
    "\n",
    "We've defined an evaluation op that computes f1 scores and other metrics for text extraction problems, in the same directory as this notebook.\n",
    "\n",
    "Just call it to run and track the evaluation for our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a8794-3e01-47e2-9dd5-3bc2a2d2da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_multi_task_f1\n",
    "evaluate_multi_task_f1(dataset_ref, regex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf217f-48e5-41ab-acc5-11f18a31f107",
   "metadata": {},
   "source": [
    "Click the link for the evaluation op printed above to see the results in the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7b505-9cb3-4f4f-a4e9-af5002976ea0",
   "metadata": {},
   "source": [
    "## Using an LLM\n",
    "\n",
    "Here we define a new model that uses OpenAI to extract the fields we want.\n",
    "\n",
    "We use the `from weave.monitoring import openai` openai API wrapper to ensure the actual OpenAI calls are logged, in addition to the calls to our outer predict method.\n",
    "\n",
    "We parameterize our model with the OpenAI model name, and the prompt template to use. So we'll get a new version of our model in the UI if we try with a different OpenAI model, or a different prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f8d4a-c9c3-4a96-8415-41a874d37cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.type()\n",
    "class OpenAIChatModel(weave.Model):\n",
    "    model_name: str\n",
    "    prompt_template: str\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, doc: str) -> typing.Any:\n",
    "        import json\n",
    "        from weave.monitoring import openai\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {'role': 'user',\n",
    "                 'content': self.prompt_template.format(doc=doc)}])\n",
    "        result = response['choices'][0]['message']['content']\n",
    "        parsed = json.loads(result)\n",
    "        return {\n",
    "            'name': parsed['name'],\n",
    "            'shares': int(parsed['shares'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b8b36-d04d-44b5-aed3-75e9c893eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIChatModel(\n",
    "    'gpt-3.5-turbo',\n",
    "    \"Extract company name (name) and number of shares (shares) from the following Articles of Incorporation document, as a json object: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a824e77-5994-4c1b-a23b-72fae15b07b3",
   "metadata": {},
   "source": [
    "Let's call the model.\n",
    "\n",
    "Sometimes this model results in an exception, because OpenAI returns invalid json, which we then try to json.loads. If you run the following cell a few times, you'll see this happen.\n",
    "\n",
    "That's ok! Weave will track raised Exceptions from ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7156a-8dc4-4616-8209-aa9f223e9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.predict(example_doc)\n",
    "except Exception as e:\n",
    "    print('Exception:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667f440-3038-4024-a344-0b965462d52f",
   "metadata": {},
   "source": [
    "Now let's evaluate the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149c23f-a56e-4693-ad88-75c9bb2b88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_multi_task_f1(dataset_ref, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1d51b-cdd0-46d9-9b77-d1f34d730e71",
   "metadata": {},
   "source": [
    "The LLM model is much more accurate already, and there's plenty we can do from here to improve it.\n",
    "\n",
    "Take a look at the UI. Click the row in the evaluation that was just created to see the details of this run. You'll see a trace of it's execution, which shows that some of the calls failed due to invalid json output.\n",
    "\n",
    "Try to fix the prompt to improve the json output and try again!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
